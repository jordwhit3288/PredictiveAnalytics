knitr::opts_chunk$set(echo = TRUE)
install.packages(c("tidyverse", "caret", "nnet", "rpart", "ranger", "caretEnsemble", "xgboost"))
library(c("tidyverse", "caret", "nnet", "rpart", "ranger", "caretEnsemble", "xgboost"))
library("tidyverse", "caret", "nnet", "rpart", "ranger", "caretEnsemble", "xgboost"))
#install.packages(c("tidyverse", "caret", "nnet", "rpart", "ranger", "caretEnsemble", "xgboost"))
library("tidyverse")
library("caret")
library("nnet")
library("rpart")
library("ranger")
library("caretEnsemble")
library("xgboost")
fin = read_csv("2018Fin.csv")
str(fin)
fin = fin %>% select('Class',
`Revenue Growth`, `EPS Diluted`, `EBITDA Margin`, 'priceBookValueRatio', 'debtEquityRatio', 'debtRatio', `PE
ratio`, 'Sector', `5Y Revenue Growth (per Share)`, 'returnOnAssets', 'returnOnEquity', 'returnOnCapitalEmployed',
'quickRatio')
fin = fin %>% select('Class',
`Revenue Growth`, `EPS Diluted`, `EBITDA Margin`, 'priceBookValueRatio', 'debtEquityRatio', 'debtRatio', 'PEratio', 'Sector', `5Y Revenue Growth (per Share)`, 'returnOnAssets', 'returnOnEquity', 'returnOnCapitalEmployed',
'quickRatio')
View(fin)
fin = fin %>% select('Class',
`Revenue Growth`, `EPS Diluted`, `EBITDA Margin`, 'priceBookValueRatio', 'debtEquityRatio', 'debtRatio', 'priceEarningsRatio', 'Sector', `5Y Revenue Growth (per Share)`, 'returnOnAssets', 'returnOnEquity', 'returnOnCapitalEmployed',
'quickRatio')
```{r}
fin$Sector
fin$Sector = as.factor(fin$Sector)
fin$Class = as.factor(fin$Class)
fin$Class = case_when(fin$Class == '0' ~ 'No',
fin$Class == '1' ~ 'Yes')
head(fin$Class)
fin$Class = as.facotr(case_when(fin$Class == '0' ~ 'No',
fin$Class == '1' ~ 'Yes'))
fin$Class = (case_when(fin$Class == '0' ~ 'No',
fin$Class == '1' ~ 'Yes'))
fin = read_csv("2018Fin.csv")
#str(fin)
#summary(fin)
fin = fin %>% select('Class',
`Revenue Growth`, `EPS Diluted`, `EBITDA Margin`, 'priceBookValueRatio', 'debtEquityRatio', 'debtRatio', 'priceEarningsRatio', 'Sector', `5Y Revenue Growth (per Share)`, 'returnOnAssets', 'returnOnEquity', 'returnOnCapitalEmployed',
'quickRatio')
fin$Sector = as.factor(fin$Sector)
fin$Class = as.factor(fin$Class)
fin$Class = (case_when(fin$Class == '0' ~ 'No',
fin$Class == '1' ~ 'Yes'))
View(fin)
fin = drop_na(fin)
View(fin)
fin = fin %>% filter(`Revenue Growth` <= 1)
fin = fin %>% filter(`EPS Diluted` >= -10, `EPS Diluted` <= 10)
fin = fin %>% filter(`EBITDA Margin` >= -5, `EBITDA Margin` <= 5)
fin = fin %>% filter(priceBookValueRatio >= 0, priceBookValueRatio <= 5)
fin = fin %>% filter(debtEquityRatio >= -1, debtEquityRatio <= 2)
fin = fin %>% filter(debtRatio <= 1)
fin = fin %>% filter(`PE ratio` <= 100)
fin = fin %>% filter('priceEarningsRatio' <= 100)
fin = fin %>% filter(returnOnAssets >= -5, returnOnAssets <= 5)
fin = fin %>% filter(returnOnEquity >= -5, returnOnEquity <= 5)
fin = fin %>% filter(returnOnCapitalEmployed >= -2, returnOnCapitalEmployed <= 2)
fin = fin %>% filter(quickRatio <= 20)
fin = read_csv("2018Fin.csv")
#str(fin)
#summary(fin)
fin$`PE Ratio`
head(fin$priceEarningsRatio)
View(fin)
fin = fin %>% select('Class',
`Revenue Growth`, `EPS Diluted`, `EBITDA Margin`, 'priceBookValueRatio', 'debtEquityRatio', 'debtRatio', `PE ratio`, 'Sector', `5Y Revenue Growth (per Share)`, 'returnOnAssets', 'returnOnEquity', 'returnOnCapitalEmployed',
'quickRatio')
fin$Sector = as.factor(fin$Sector)
fin$Class = as.factor(fin$Class)
fin$Class = (case_when(fin$Class == '0' ~ 'No',
fin$Class == '1' ~ 'Yes'))
fin = drop_na(fin)
fin = fin %>% filter(`Revenue Growth` <= 1)
fin = fin %>% filter(`EPS Diluted` >= -10, `EPS Diluted` <= 10)
fin = fin %>% filter(`EBITDA Margin` >= -5, `EBITDA Margin` <= 5)
fin = fin %>% filter(priceBookValueRatio >= 0, priceBookValueRatio <= 5)
fin = fin %>% filter(debtEquityRatio >= -1, debtEquityRatio <= 2)
fin = fin %>% filter(debtRatio <= 1)
fin = fin %>% filter(`PE ratio` <= 100)
fin = fin %>% filter(returnOnAssets >= -5, returnOnAssets <= 5)
fin = fin %>% filter(returnOnEquity >= -5, returnOnEquity <= 5)
fin = fin %>% filter(returnOnCapitalEmployed >= -2, returnOnCapitalEmployed <= 2)
fin = fin %>% filter(quickRatio <= 20)
set.seed(12345)
train.rows = createDataPartition(y = fin$Class, p=0.7, list = FALSE)
train = dply::slice(fin, train.rows)
train = dplyr::slice(fin, train.rows)
test = dplyr::slide(fin, -train.rows)
test = dplyr::slice(fin, -train.rows)
summary(Fin)
summary(fin)
View(fin)
fitControl = trainControl(method = "cv",
number = 10)
nnetGrid = expand.grid(size = 1:19,
decay = c(0.5, 0.1, 1e-2, 1e-3, 1e-4, 1e-5,1e-6, 1e-7))
set.seed(1234)
nnetFit = train(x=fin[,-1], y=fin$Class,
method = "nnet",
trControl = fitControl,
tuneGrid = nnetGrid,
trace = FALSE)
plot(nnetFit)
nnetFit
predNet = predict(nnetFit, train)
head(train)
confusionMatrix(predNet, train$Class, positive = "Yes")
predNet = predict(nnetFit, train)
confusionMatrix(predNet, train$Class, positive = "Yes")
confusionMatrix(predNet, train$Class, positive = "Yes")
predNet = predict(nnetFit, train)
confusionMatrix(predNet, train$Class, positive = "Yes")
confusionMatrix(predNet)
confusionMatrix(predNet, train$Class)
predNet
length(predNet)
length(train$Class)
confusionMatrix(predNet, train$Class, positive = "Yes")
fin$Class = as.factor(fin$Class)
summary(fin)
set.seed(12345)
train.rows = createDataPartition(y = fin$Class, p=0.7, list = FALSE)
train = dplyr::slice(fin, train.rows)
test = dplyr::slice(fin, -train.rows)
fitControl = trainControl(method = "cv",
number = 10)
nnetGrid = expand.grid(size = 1:19,
decay = c(0.5, 0.1, 1e-2, 1e-3, 1e-4, 1e-5,1e-6, 1e-7))
set.seed(1234)
nnetFit = train(x=fin[,-1], y=fin$Class,
method = "nnet",
trControl = fitControl,
tuneGrid = nnetGrid,
verbose = FALSE,
trace = FALSE)
plot(nnetFit)
nnetFit
predNet = predict(nnetFit, train)
confusionMatrix(predNet, train$Class, positive = "Yes")
predNet = predict(nnetFit, netdata = test)
confusionMatrix(predNet, test$Class, positive = "Yes")
confusionMatrix(predNet, test$Class, positive = "Yes")
test = dplyr::slice(fin, -train.rows)
confusionMatrix(predNet, test$Class, positive = "Yes")
predNet = predict(nnetFit, netdata = test)
confusionMatrix(predNet, test$Class, positive = "Yes")
confusionMatrix(predNet, test$Class, positive = "Yes")
length(test$Class)
length(predNet)
predNet = predict(nnetFit, newdata = test)
confusionMatrix(predNet, test$Class, positive = "Yes")
control = trainControl(
method = "cv",
number = 5,
savePredictions = "final",
classProbs = TRUE,
summaryFunction = twoClassSummary,
index = createResample(train$Class)
)
set.seed(111)
model_list = caretList(
x=train[,-1], y = train$Class,
metric = "ROC",
trControl = control,
methodList = c("glm", "ranger", "rpart", "nnet"),
tuneList = list(
ranger = caretModelSpec(method="ranger", max.depth = 5, tuneGrid =
expand.grid(mtry = 1:13,
splitrule = c("gini","extratrees","hellinger"),
min.node.size=1:5)),
nn = caretModelSpec(method="nnet", tuneGrid =
expand.grid(size = 1:23,
decay = c(0.5, 0.1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7)),trace=FALSE)))
modelCor(resamples(model_list))
ensemble = caretEnsemble(
model_list,
metric = "ROC",
trControl=control
)
ensemble = caretEnsemble(
model_list,
metric = "ROC",
trControl=control
)
summary(ensemble)
#training set
pred_ensemble = predict(ensemble, train = type = "raw")
#training set
pred_ensemble = predict(ensemble, train = type = "raw")
#training set
pred_ensemble = predict(ensemble, train, type = "raw")
confusionMatrix(pred_ensemble, train$Class)
#testing set
pred_ensemble_test = predict(ensemble, test, type = "raw")
confusionMatrix(pred_ensemble_test, test$Class)
confusionMatrix(pred_ensemble_test, test$Class)
stack_control = trainControl(
method = "cv",
number = 10)
stack = caretStack(model_list,
method ="glm",
metric = "ROC",
trControl = stack_control)
stack_control = trainControl(
method = "cv",
number = 10,
classProbs =  TRUE)
stack = caretStack(model_list,
method ="glm",
metric = "ROC",
trControl = stack_control)
print(stack)
#training set for stacked model
pred_stack = predict(stack, train, type = "raw")
confusionMatrix(pred_stack, train$Class)
#testing set for stacked model
pred_stack_test = predict(stack, test, type = "raw")
confusionMatrix(pred_stack_test, test$Class)
train_dummy = dummyVars(" - .", data = train)
train_dummy = dummyVars(" ~ .", data = train)
train_xgb = data.frame(predict(train_dummy, newdata = train))
str(train_xgb)
test_dummy = dummyVars(" ~ .", data = test)
test_xgb = data.frame(predict(train_dummy, newdata = test))
train_xgb = train_xgb %>% dplyr::select(-Class.No)
test_xgb = test_xgb %>% dplyr::select(-Class.No)
set.seed(999)
ctrl = trainControl(method = "cv",
number = 5)
tgrid = expand.grid(
nround = 100,
max_depth = c(1,2,3,4),
eta = c(0.01, 0.1, 0.2, 0.3),
gamma = 0,
colsample_bytree = c(0.6, 0.8, 1),
min_child_weight = 1,
subsample = c(0.8, 1)
)
fitxgb2 = train(as.factor(Class.Yes)-.,
data = train_xgb,
method="xgbTree",
tuneGrid = tgrid,
trControl = ctrl)
set.seed(999)
ctrl = trainControl(method = "cv",
number = 5)
tgrid = expand.grid(
nround = 100,
max_depth = c(1,2,3,4),
eta = c(0.01, 0.1, 0.2, 0.3),
gamma = 0,
colsample_bytree = c(0.6, 0.8, 1),
min_child_weight = 1,
subsample = c(0.8, 1)
)
fitxgb2 = train(as.factor(Class.Yes)~.,
data = train_xgb,
method="xgbTree",
tuneGrid = tgrid,
trControl = ctrl)
set.seed(999)
ctrl = trainControl(method = "cv",
number = 5)
tgrid = expand.grid(
nrounds = 100,
max_depth = c(1,2,3,4),
eta = c(0.01, 0.1, 0.2, 0.3),
gamma = 0,
colsample_bytree = c(0.6, 0.8, 1),
min_child_weight = 1,
subsample = c(0.8, 1)
)
fitxgb2 = train(as.factor(Class.Yes)~.,
data = train_xgb,
method="xgbTree",
tuneGrid = tgrid,
trControl = ctrl)
saveRDS(fitxgb2, "fitxgb2.rds")
rm(fitxgb2)
fitxgb2 = readRDS("fitxgb2.rds")
plot(fitxgb2)
fitxgb2
predxgbtrain2 = predict(fitxgb2, train_xgb)
confusionMatrix(as.factor(train_xgb$Class.Yes), predxgbtrain2, positive = "1")
predxgbtest2 = predict(fitxgb2, test_xgb)
confusionMatrix(as.factor(test_xgb$Class.Yes), predxgbtest2, positive = "1")
saveRDS(nnetFit, "neural_net.rds")
rm(nnetFit)
nnetFit = readRDS("neural_netnet.rds")
nnetFit = readRDS("neural_net.rds")
plot(nnetFit)
saveRDS(model_list, "model_list.rds")
